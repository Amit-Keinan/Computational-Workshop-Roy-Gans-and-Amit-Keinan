{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'conf' from '/Volumes/homes/Maya/Guests/Amit/CompSagolProj/conf.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as sc\n",
    "import conf\n",
    "import importlib\n",
    "import os\n",
    "import random\n",
    "importlib.reload(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_mean(region_idx, data, atlas_cifti_data):\n",
    "    \"\"\"\n",
    "    Compute the mean timeseries for a brain region.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    region_idx : int\n",
    "        Index of the brain region to extract from the atlas.\n",
    "    data : np.array\n",
    "        Functional timeseries data of shape (timepoints, vertices).\n",
    "    atlas_cifti_data : np.array\n",
    "        Atlas label data indicating the region assignment for each voxel.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    region_timeseries : np.array\n",
    "        Mean timeseries of the specified region.\n",
    "    \"\"\"\n",
    "    region_vertices_mask = atlas_cifti_data == region_idx\n",
    "    region_timeseries = np.mean(data[:,region_vertices_mask[0]], axis = 1)\n",
    "    return region_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_same_program_subjs(curr_subj, curr_subj_program, map_prog_to_subj):\n",
    "    \"\"\"\n",
    "    Extract list of subjects with the same academic program affiliation as the current subject given as param\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    curr_subj : str\n",
    "        ID of the current subject.\n",
    "    curr_subj_program : str\n",
    "        The program that the current subject is enrolled in.\n",
    "    map_prog_to_subj : dict\n",
    "        Dictionary mapping each program to a list of subject identifiers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    same_program_subjs : list of str\n",
    "        List of subject identifiers in the same program, excluding the current subject.\n",
    "    \"\"\"\n",
    "    return [subj for program, subjs in map_prog_to_subj.items() if program == curr_subj_program for subj in subjs if subj != curr_subj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_program_subjs(curr_program, map_prog_to_subj, comp_subj_cnt):\n",
    "    \"\"\"\n",
    "    Extract list of subjects with a different academic program affiliation as the current subject given as param, randomly sampling the number of subjects to match the ingroup size for comparison.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    curr_program : str\n",
    "        Name of the current program.\n",
    "    map_prog_to_subj : dict\n",
    "        Dictionary mapping each program to a list of subject identifiers.\n",
    "    comp_subj_cnt : int\n",
    "        Number of subjects to match the ingroup size for comparison.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sampled_subjs : list of str\n",
    "        List of subject identifiers from different programs.\n",
    "    \"\"\"\n",
    "    diff_subj_list =  [subj for program, subjs in map_prog_to_subj.items() if program != curr_program for subj in subjs]\n",
    "    return random.sample(diff_subj_list, comp_subj_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_subjs_data(time_point, category_prefix, relevant_subjs):\n",
    "    \"\"\"\n",
    "    Calculate the mean voxel activity for a group of subjects at a specific time point and stimulus category.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time_point : str\n",
    "        Identifier for the time point used to locate the fMRI data.\n",
    "    category_prefix : str\n",
    "        Prefix specifying the stimulus category, an empty string '' indicates all categories.\n",
    "    relevant_subjs : list of str\n",
    "        List of subject identifiers to include in the mean calculation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mean_subjs_data : np.array\n",
    "        average voxel activity across subjects.\n",
    "    \"\"\"\n",
    "    if category_prefix == '': # All categories (6 movies)\n",
    "        time_series = conf.FMRI_TIMESERIES_ALL_CATEGORIES\n",
    "    else: # Specific category (2 movies)\n",
    "        time_series = conf.FMRI_TIMESERIES_ONE_CATEGORY\n",
    "\n",
    "    # Create an empty matrix to calculate the mean\n",
    "    mean_subjs_data = np.zeros((time_series, conf.N_VOXELS))\n",
    "\n",
    "    for subj in relevant_subjs: # Sum relevant subjects data\n",
    "        \n",
    "        cifti_path = f'{conf.ROOT_PATH}/{time_point}/{subj}/MNINonLinear/Results/movies_concat_data/{category_prefix}movies_concat_data_AP_Atlas_MSMAll_hp2000_clean.dtseries.nii'\n",
    "        load_cifti = nib.load(cifti_path)\n",
    "        cifti_data = load_cifti.get_fdata()\n",
    "        mean_subjs_data += cifti_data\n",
    "        \n",
    "    mean_subjs_data = mean_subjs_data / len(relevant_subjs)\n",
    "    \n",
    "    return mean_subjs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute mean Engineering_Biology\n",
      "compute mean Physics\n",
      "compute mean Psychology_Biology\n",
      "compute mean Psychology_Computer_Science\n",
      "Analyzing first_time_point neutral_ scan of subject 001\n",
      "Analyzing first_time_point neutral_ scan of subject 002\n",
      "Analyzing first_time_point neutral_ scan of subject 003\n",
      "Analyzing first_time_point neutral_ scan of subject 004\n",
      "Analyzing first_time_point neutral_ scan of subject 005\n",
      "Analyzing first_time_point neutral_ scan of subject 006\n",
      "Analyzing first_time_point neutral_ scan of subject 007\n",
      "Analyzing first_time_point neutral_ scan of subject 008\n",
      "Analyzing first_time_point neutral_ scan of subject 009\n",
      "Analyzing first_time_point neutral_ scan of subject 012\n",
      "Analyzing first_time_point neutral_ scan of subject 014\n",
      "Analyzing first_time_point neutral_ scan of subject 015\n",
      "Analyzing first_time_point neutral_ scan of subject 016\n",
      "Analyzing first_time_point neutral_ scan of subject 018\n",
      "Analyzing first_time_point neutral_ scan of subject 019\n",
      "Analyzing first_time_point neutral_ scan of subject 020\n",
      "Analyzing first_time_point neutral_ scan of subject 022\n",
      "Analyzing first_time_point neutral_ scan of subject 023\n",
      "Analyzing first_time_point neutral_ scan of subject 025\n",
      "Analyzing first_time_point neutral_ scan of subject 028\n",
      "Analyzing first_time_point neutral_ scan of subject 029\n",
      "Analyzing first_time_point neutral_ scan of subject 032\n"
     ]
    }
   ],
   "source": [
    "# Extract atlas cifti file and number of regions inside it\n",
    "ATLAS_CIFTI  = nib.load(conf.ATLAS_CIFTI_PATH).get_fdata()\n",
    "N_REGIONS = int(np.max(ATLAS_CIFTI))\n",
    "\n",
    "# Load behavioral data of fMRI participants\n",
    "behav_data_df = pd.read_excel('/Volumes/homes/Maya/Guests/Amit/behav_data.xlsx')\n",
    "behav_data_df = behav_data_df[~behav_data_df['subj'].astype(str).isin(conf.EXCLUDED)]\n",
    "behav_data_df['subj_formatted'] = behav_data_df['subj'].astype(str).str.zfill(3)\n",
    "\n",
    "# Create a dict for mapping program with it's corresponded affiliated subjects\n",
    "map_prog_to_subj = behav_data_df.groupby('program')['subj_formatted'].apply(list).to_dict()\n",
    "\n",
    "for time_point in conf.TIME_POINTS:\n",
    "\n",
    "    for category_prefix in conf.SCANS_CATEGORIES_PREFIX:\n",
    "        \n",
    "        # Lists to store data before creating a DataFrame\n",
    "        same_prog_corr_list = []\n",
    "        diff_prog_corr_list = []\n",
    "        \n",
    "        # Compute mean of diff programs using random sampling to match ingroup size for comparison\n",
    "        map_prog_to_mean_diff = {}\n",
    "        for prog in map_prog_to_subj.keys():\n",
    "            comp_subj_cnt = len(map_prog_to_subj[prog]) - 1\n",
    "            diff_prog_subjs = get_diff_program_subjs(prog, map_prog_to_subj, comp_subj_cnt)\n",
    "            print(f\"compute mean {prog}\")\n",
    "            map_prog_to_mean_diff[prog] = calc_mean_subjs_data(time_point, category_prefix, diff_prog_subjs)\n",
    "            \n",
    "        for idx, row in behav_data_df.iterrows():\n",
    "            subj = row['subj_formatted']\n",
    "            \n",
    "            print(f\"Analyzing {time_point} {category_prefix} scan of subject {subj}\")\n",
    "            \n",
    "            # Create a dict to store current subject data\n",
    "            same_prog_subj_row = {'subject' : subj}\n",
    "            diff_prog_subj_row = {'subject' : subj}\n",
    "\n",
    "            # Load subject's data\n",
    "            cifti_path = f'{conf.ROOT_PATH}/{time_point}/{subj}/MNINonLinear/Results/movies_concat_data/{category_prefix}movies_concat_data_AP_Atlas_MSMAll_hp2000_clean.dtseries.nii'\n",
    "            load_cifti = nib.load(cifti_path)\n",
    "            subj_i_data = load_cifti.get_fdata()\n",
    "\n",
    "            # Mean of subjects' academic program\n",
    "            same_prog_subjs = get_same_program_subjs(subj, row['program'], map_prog_to_subj)\n",
    "            same_program_mean = calc_mean_subjs_data(time_point, category_prefix, same_prog_subjs)\n",
    "            not_subject_program_mean = map_prog_to_mean_diff[row['program']]\n",
    "\n",
    "            for region in range(1, N_REGIONS+1):\n",
    "                # compute region mean from region voxels\n",
    "                timeseries_subj_i = get_region_mean(region, subj_i_data, ATLAS_CIFTI)\n",
    "                timeseries_same_program = get_region_mean(region, same_program_mean, ATLAS_CIFTI)\n",
    "                timeseries_diff_program = get_region_mean(region, not_subject_program_mean, ATLAS_CIFTI)\n",
    "\n",
    "                # correlation of subject's neural activity in brain region with same program's mean activity\n",
    "                region_same_program_corr, _ = sc.pearsonr(timeseries_subj_i, timeseries_same_program)\n",
    "                same_prog_subj_row[str(region)] = np.arctanh(region_same_program_corr) #Fisher's z transformation\n",
    "\n",
    "                # correlation of subject's neural activity in brain region with different program's mean activity\n",
    "                region_diff_program_corr, _ = sc.pearsonr(timeseries_subj_i, timeseries_diff_program)\n",
    "                diff_prog_subj_row[str(region)] = np.arctanh(region_diff_program_corr) #Fisher's z transformation\n",
    "            \n",
    "            # Append subject’s data to lists used for df creation.\n",
    "            same_prog_corr_list.append(same_prog_subj_row)\n",
    "            diff_prog_corr_list.append(diff_prog_subj_row)\n",
    "\n",
    "        # Save data to excel\n",
    "        pd.DataFrame(same_prog_corr_list).to_csv(os.path.join(conf.OUTPUT_PATH_DIR_PREFIX, f'{time_point}_{category_prefix}same_prog_corr.csv'), index=False)\n",
    "        pd.DataFrame(diff_prog_corr_list).to_csv(os.path.join(conf.OUTPUT_PATH_DIR_PREFIX, f'{time_point}_{category_prefix}diff_prog_corr.csv'), index=False)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize values within region across subjects\n",
    "\n",
    "for time_point in conf.TIME_POINTS:\n",
    "\n",
    "    for category_prefix in conf.SCANS_CATEGORIES_PREFIX:\n",
    "        # load data\n",
    "        same_prog_df = pd.read_csv(os.path.join(conf.OUTPUT_PATH_DIR_PREFIX, f'{time_point}_{category_prefix}same_prog_corr.csv'))\n",
    "        diff_prog_df = pd.read_csv(os.path.join(conf.OUTPUT_PATH_DIR_PREFIX, f'{time_point}_{category_prefix}diff_prog_corr.csv'))\n",
    "\n",
    "        # concat dfs in order to normalize\n",
    "        concat_df = pd.concat([same_prog_df, diff_prog_df], ignore_index=True)\n",
    "\n",
    "        # remove the first column of subject ids to avoid normalizing it\n",
    "        subjects = concat_df['subject']\n",
    "        concat_df = concat_df.drop(columns = ['subject'])\n",
    "\n",
    "        norm_df = (concat_df - concat_df.mean(axis = 0))/concat_df.std(axis = 0)\n",
    "\n",
    "        # add the subject ids column back\n",
    "        norm_df.insert(0, 'subject', subjects)\n",
    "\n",
    "        # divide the combined pdf back to same and diff prog\n",
    "        norm_same_prog_df = norm_df[:33]\n",
    "        norm_diff_prog_df = norm_df[-33:]\n",
    "        \n",
    "        # save normalized data\n",
    "        norm_same_prog_df.to_csv(os.path.join(conf.OUTPUT_PATH_DIR_PREFIX, f'normalized_data/norm_{time_point}_{category_prefix}same_prog_corr.csv'), index=False)\n",
    "        norm_diff_prog_df.to_csv(os.path.join(conf.OUTPUT_PATH_DIR_PREFIX, f'normalized_data/norm_{time_point}_{category_prefix}diff_prog_corr.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.3-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading openpyxl-3.1.3-py2.py3-none-any.whl (251 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.3/251.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
